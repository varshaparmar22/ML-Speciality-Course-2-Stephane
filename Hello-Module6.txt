29,40,49,58 question revise

Date :  04/06/2024

==> Build your own alexa

-> input = speech , output = speech
-> amazon transcribe -> amazon lex automated designer -> amazon polly

==> Build your own universal translator

-> input = speech , output = speech
-> amazon transcribe -> amazon translate -> amazon polly

==> Build your own celebrity detector

-> input deeplence device and associate with recognition and fire alarm is show celebrity specified
-> aws deeplence -> amazon recognition

==> Build system to check people calling you are happy or sad or sentiment any

-> input = speech, output = sentiment with score
-> amazon transcribe -> amazon comprehend


@@@@@@@@@@@@@@@@@@@ Algo Content Type @@@@@@@@@@@@@@@@

ContentType============>Algorithm
application/x-imag============>Object Detection Algorithm, Semantic Segmentation
application/x-recordio============>Object Detection Algorithm

application/x-recordio-protobuf============>Factorization Machines, K-Means, k-NN, LDA, Linear Learner, NTM, PCA, RCF, Sequence-to-Sequence

application/jsonlines============>BlazingText, DeepAR

image/jpeg============>Object Detection Algorithm, Semantic Segmentation

image/png============>Object Detection Algorithm, Semantic Segmentation

text/csv============>IP Insights, K-Means, k-NN, Latent Dirichlet Allocation, Linear Learner, NTM, PCA, RCF, XGBoost

text/libsvm============>XGBoost

@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

@@@@@@@@@@@@ model implementing @@@@@@@@@@@2

accuracy => accuracy on training data
val_acc => accuracy on unseen data <- to check overfitting check this it should be high for no overfitting

- if overfitting do regularization based on algo we will choose
- if cnn then choose dropout layer to overcome overfitting

- high batch size will stuck model in local minima not good solution
- high learning rate is also same overshoot the correct solution
- small batch size required small learning rate

@@@@@@@@@@@@@@@@@@@@@ important points to remember @@@@@@@@@@@@@@@@@@@@@2

- mostly web application use port 8080

- standard http port is 80

- model artifact compressed in tar.gz file format

- if binary classification problem and threshold settings is there in option it can be most approx.  answer for FN/FP related issue

- Encryption needs to be implemented at the application layer (such as SSL/TLS) or by using AWS services designed for encryption

- Boosting- model training technique - increasing the accuracy by giving more weight to difficult to predict observations in sequential model training.

- if skewed(feature) dataset, and you need to uniform it by binning-apply quantile binning to convert it into bins having equal no of observation

- Training for more epochs often leads to overfitting, as the model starts to memorize rather than generalize from the training data.

- silhouette score if >1 data point very far from nearest cluster, 0 on one cluster or on boundary of two cluster, -1 assign in wrong cluster

- EMRFS -Hadoop file system API, allowing direct interaction between EMR-hosted applications like MapReduce & S3. By using the `s3://` file prefix.

- S3A (Amazon S3A File System) Hadoop-compatible interface for accessing data in S3-accessing public data sets without requiring AWS credentials.

- Amazon Comprehend use LDA feature - for topic modeling

- if NN has more layers than use ReLU as it solve vanishing gradient problem because of more layers for convergence

- if accuracy is not as required you can change activation function 

- if convergence issue than it is indicating problem with gradient loss - use Relu to solve it - specially if Network is complex already

- if outliers are in dataset we can use median values for imputation

- labeling by ground truth incorporates both precision and speed as it provide automatic labeling by self learning algo and human reviewing

- Reckognition in asw if custom logo or character you need to identify, fir train recoknition with labeled dataset(even a small one). final model will be created and trained and you will get api for that model to use for your specific use case - you need labeled dataset for custom reckognition

- blazing text can handle n-gram technique so it break word in subword and handle OOV by aggregating subword vector so good performance on morphologically rich language.

- access to s3 in sagemaker handled by IAM roles & policy not by bucket access control list(ACL) - role based access control 

- To protect your data in transit within the AWS Cloud, Amazon Redshift uses hardware accelerated SSL to communicate with S3 or DynamoDB for COPY, UNLOAD, backup, and restore operations.

-Trusted Advisor checks security groups for rules that allow unrestricted access to a resource. Unrestricted access increases opportunities for malicious activity, such as hacking, denial-of-service attacks, or loss of data. 

- while transferring data from firehose to destination, data transformation will be happen in lambda function

- The lambda timeout value default is 3 seconds.

- Firehose supports Amazon S3 server-side encryption with AWS Key Management Service (SSE-KMS)

- AWS auto scaling lets you scale other resources &services like ECS, dynamodb tables, aurora replicas etc just like EC2 instance scaling(add more as need)

- The AWS Glue Data Catalog is an Apache Hive metastore-compatible catalog

- to attach kinesis video stream to sagemaker direct amazon kinesis video stream inference template(KIT) is used.

- Glue classifier send certainty string either 1.0=> all schema are 100% sure or Unknown or 0.0 => all schema are not classified from given data

- Reckognition can fail to identify face if it is trained on single image per person - it need to train on multiple image of same person with different aspects like beard, glasses etc

- random forest(Supervised algo-multiple dT classification & regression) prevent overfitting just like bagging technique

- Entropy uses the probability of a certain outcome in order to make a decision on how the node should branch. Unlike the Gini index, it is more mathematical intensive due to the logarithmic function used in calculating it.

- AWS Security Token Service (AWS STS) is a web service that enables you to request temporary credentials for use in your code, CLI, or third-party tools

- Access Advisor to check when service or resource last accessed and by whom

- AWS Systems Manager Parameter Store - to store parameters like credential, licence key or configuration parameters

- AWS Secrets Manager - helps you manage, retrieve, and rotate database credentials, application credentials, OAuth tokens, API keys, and other secrets throughout their lifecycles. - built-in integration for MySQL, PostgreSQL, and Amazon Aurora on Amazon RDS

- Hinge loss is related to support vector classifier, and it not specify probability

- Heuristic approach is problem-solving methods(mathematical) that are based on practical experience and knowledge, when you are not applying ML approach

- recorIO => 4 bytes representation

- the macro average F1-measure is used to evaluate the predictive success of a multiclass classifier. 

- model quantization reduce model size and inference time for edge device with little loss of accuracy.

- for edge device cloud based inference will introduce latency

- knowledge distillation is creating new model having smaller size, but need to train it and optimize for edge device

- image down-sampling will risk loosing smaller details
